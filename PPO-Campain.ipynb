{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e76814-2083-496f-9cba-835f02a7fa47",
   "metadata": {},
   "source": [
    "# PPO- based Pysc2\n",
    "\n",
    "Modular Design\n",
    "sc2_ppo_project/\n",
    "\n",
    "├── main.py             # Entry-point to run training\n",
    "\n",
    "├── config.py           # Hyperparameters and logging config\n",
    "\n",
    "├── environment.py      # SC2 environment wrapper\n",
    "\n",
    "├── model.py            # Actor-Critic neural network\n",
    "\n",
    "├── utils.py            # Observation preprocessing and action utilities\n",
    "\n",
    "└── ppo.py              # PPO training algorithm implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f92e15-9658-4ec9-8e6c-2b6e7769257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9344929d-431d-4821-8768-35f16cb59ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "# ─── Hyperparameters ─────────────────────────────\n",
    "# MAP_NAME     = \"CollectMineralsAndGas\"\n",
    "MAP_NAME     = \"Simple64\"\n",
    "\n",
    "SCREEN_SIZE  = 84\n",
    "MINIMAP_SIZE = 64\n",
    "STEP_MUL     = 16\n",
    "NB_ACTORS    = 1\n",
    "T            = 128\n",
    "K            = 10\n",
    "BATCH_SIZE   = 256\n",
    "GAMMA        = 0.99\n",
    "GAE_LAMBDA   = 0.95\n",
    "LR           = 2.5e-4\n",
    "ENT_COEF     = 0.01\n",
    "VF_COEF      = 1.0\n",
    "MAX_ITERS    = 10000\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─── Logging Configuration ──────────────────────\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c30bd3-1eff-4263-93d8-d42fc320ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656af9d7-6973-448b-b4f6-a6ca44b13d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "# from config import MAP_NAME, SCREEN_SIZE, MINIMAP_SIZE, STEP_MUL, logger\n",
    "\n",
    "class SC2Envs:\n",
    "    def __init__(self, nb_actor):\n",
    "        logger.info(\"Initializing %d SC2 env(s)...\", nb_actor)\n",
    "        self.nb   = nb_actor\n",
    "        self.envs = [self._make_env() for _ in range(nb_actor)]\n",
    "        self.obs  = [None]*nb_actor\n",
    "        self.done = [False]*nb_actor\n",
    "        self._init_all()\n",
    "        logger.info(\"All SC2 env(s) ready.\")\n",
    "\n",
    "    def _make_env(self):\n",
    "        return sc2_env.SC2Env(\n",
    "            map_name=MAP_NAME,\n",
    "            players=[sc2_env.Agent(sc2_env.Race.terran)],\n",
    "            agent_interface_format=features.AgentInterfaceFormat(\n",
    "                feature_dimensions=features.Dimensions(\n",
    "                    screen=SCREEN_SIZE, minimap=MINIMAP_SIZE),\n",
    "                use_feature_units=True,\n",
    "                use_raw_units=False,\n",
    "                use_camera_position=True,\n",
    "                action_space=actions.ActionSpace.FEATURES\n",
    "            ),\n",
    "            step_mul=STEP_MUL,\n",
    "            game_steps_per_episode=0,\n",
    "            visualize=False,\n",
    "        )\n",
    "\n",
    "    def _init_all(self):\n",
    "        for i, e in enumerate(self.envs):\n",
    "            ts = e.reset()[0]\n",
    "            self.obs[i], self.done[i] = ts, False\n",
    "\n",
    "    def reset(self, i):\n",
    "        ts = self.envs[i].reset()[0]\n",
    "        self.obs[i], self.done[i] = ts, False\n",
    "        return ts\n",
    "\n",
    "    def step(self, i, fc):\n",
    "        ts = self.envs[i].step([fc])[0]\n",
    "        self.obs[i], self.done[i] = ts, ts.last()\n",
    "        return ts\n",
    "\n",
    "    def close(self):\n",
    "        for e in self.envs:\n",
    "            e.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009ecfc0-4629-46d1-9c03-55c6733f10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi Plaer Map\n",
    "\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "import logging\n",
    "\n",
    "class SC2EnvsMulti:\n",
    "    def __init__(self, nb_actor):\n",
    "        logger.info(\"Initializing %d SC2 env(s)...\", nb_actor)\n",
    "        self.nb = nb_actor\n",
    "        self.envs = [self._make_env() for _ in range(nb_actor)]\n",
    "        self.obs = [env.reset()[0] for env in self.envs]\n",
    "        self.done = [False] * nb_actor\n",
    "\n",
    "    def _make_env(self):\n",
    "        return sc2_env.SC2Env(\n",
    "            map_name=MAP_NAME,\n",
    "            players=[\n",
    "                sc2_env.Agent(sc2_env.Race.terran),\n",
    "                sc2_env.Bot(sc2_env.Race.terran, sc2_env.Difficulty.very_easy)\n",
    "\n",
    "            ],\n",
    "            agent_interface_format=features.AgentInterfaceFormat(\n",
    "                feature_dimensions=features.Dimensions(\n",
    "                    screen=SCREEN_SIZE, minimap=MINIMAP_SIZE),\n",
    "                use_feature_units=True,\n",
    "                use_raw_units=False,\n",
    "                use_camera_position=True,\n",
    "                action_space=actions.ActionSpace.FEATURES\n",
    "            ),\n",
    "            step_mul=STEP_MUL,\n",
    "            game_steps_per_episode=0,\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "    def step(self, i, action):\n",
    "        timestep = self.envs[i].step([action])[0]\n",
    "        self.obs[i] = timestep\n",
    "        self.done[i] = timestep.last()\n",
    "        return timestep\n",
    "\n",
    "    def reset(self, i):\n",
    "        self.obs[i] = self.envs[i].reset()[0]\n",
    "        self.done[i] = False\n",
    "\n",
    "    def close(self):\n",
    "        for env in self.envs:\n",
    "            env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f776099f-7adf-49ec-b782-9b7d1f38d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d359419f-72a0-4747-aeec-d3cdb502bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from config import SCREEN_SIZE, DEVICE\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, in_channels, nb_actions):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 8, stride=4), nn.Tanh(),\n",
    "            nn.Conv2d(16, 32, 4, stride=2), nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, SCREEN_SIZE, SCREEN_SIZE)\n",
    "            conv_out = self.conv(dummy).shape[-1]\n",
    "\n",
    "        self.fc     = nn.Sequential(nn.Linear(conv_out, 256), nn.Tanh())\n",
    "        self.actor  = nn.Linear(256, nb_actions)\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.fc(h)\n",
    "        return self.actor(h), self.critic(h).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70587f2-7223-4547-afe0-6a9f1c26f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28143d60-a430-4f01-829a-f1278b94f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from pysc2.lib import actions, features\n",
    "# # from config import DEVICE\n",
    "\n",
    "# _PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "# _UNIT_TYPE       = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "# ACTION_LIST = ['do_nothing', 'select_idle', 'build_refinery', 'harvest']\n",
    "# FUNC_ID = {\n",
    "#     'do_nothing': actions.FUNCTIONS.no_op.id,\n",
    "#     'select_idle': actions.FUNCTIONS.select_idle_worker.id,\n",
    "#     'build_refinery': actions.FUNCTIONS.Build_Refinery_screen.id,\n",
    "#     'harvest': actions.FUNCTIONS.Harvest_Gather_screen.id,\n",
    "# }\n",
    "\n",
    "# def preprocess(ts):\n",
    "#     fs = ts.observation.feature_screen\n",
    "#     pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "#     ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "#     stacked = np.stack([pr, ut], axis=0)\n",
    "#     return torch.from_numpy(stacked).unsqueeze(0).float().to(DEVICE)\n",
    "\n",
    "# def legal_actions(ts):\n",
    "#     avail = set(ts.observation.available_actions)\n",
    "#     fus   = ts.observation.feature_units\n",
    "#     legal = [0]\n",
    "#     if FUNC_ID['select_idle'] in avail: legal.append(1)\n",
    "#     if FUNC_ID['build_refinery'] in avail and any(u.unit_type==342 for u in fus): legal.append(2)\n",
    "#     if FUNC_ID['harvest'] in avail and any(u.unit_type==341 for u in fus): legal.append(3)\n",
    "#     return legal\n",
    "\n",
    "# def make_pysc2_call(action_idx, ts):\n",
    "#     name, fid = ACTION_LIST[action_idx], FUNC_ID[ACTION_LIST[action_idx]]\n",
    "#     if name == 'select_idle':\n",
    "#         return actions.FunctionCall(fid, [[2]])\n",
    "#     if name in ('build_refinery','harvest'):\n",
    "#         fus = ts.observation.feature_units\n",
    "#         cand = [u for u in fus if (u.unit_type==342 if name=='build_refinery' else u.unit_type==341)]\n",
    "#         if not cand:\n",
    "#             return actions.FunctionCall(actions.FUNCTIONS.no_op.id, [])\n",
    "#         u = random.choice(cand)\n",
    "#         return actions.FunctionCall(fid, [[0],[u.x,u.y]])\n",
    "#     return actions.FunctionCall(fid, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9259464-83a6-4c0d-a9a9-7b536dd1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pysc2.lib import actions, features\n",
    "\n",
    "_PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "_UNIT_TYPE = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "ACTION_LIST = ['do_nothing', 'move', 'attack', 'build', 'gather', 'upgrade', 'train']\n",
    "ACTION_INDEX = {name: idx for idx, name in enumerate(ACTION_LIST)}\n",
    "\n",
    "SCREEN_SIZE = 84\n",
    "\n",
    "# Terran building unit_type IDs (partial list — expand as needed)\n",
    "TERRAN_STRUCTURE_TYPES = [\n",
    "    18,   # CommandCenter\n",
    "    20,   # SupplyDepot\n",
    "    21,   # Barracks\n",
    "    22,   # EngineeringBay\n",
    "    23,   # MissileTurret\n",
    "    24,   # Bunker\n",
    "    25,   # Refinery\n",
    "    27,   # Factory\n",
    "    28,   # GhostAcademy\n",
    "    29,   # Starport\n",
    "    30,   # Armory\n",
    "    130, 131, 132, 133  # Tech lab, Reactor, etc.\n",
    "]\n",
    "\n",
    "def safe_coords(x, y, screen_size=SCREEN_SIZE):\n",
    "    x = max(0, min(screen_size - 1, x))\n",
    "    y = max(0, min(screen_size - 1, y))\n",
    "    return [x, y]\n",
    "\n",
    "def preprocess(ts):\n",
    "    fs = ts.observation.feature_screen\n",
    "    pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "    ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "    stacked = np.stack([pr, ut], axis=0)\n",
    "    return torch.from_numpy(stacked).unsqueeze(0).float()\n",
    "\n",
    "def legal_actions(ts):\n",
    "    avail = set(ts.observation.available_actions)\n",
    "    fus = ts.observation.feature_units\n",
    "    legal = [ACTION_INDEX['do_nothing']]\n",
    "\n",
    "    if actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['move'])\n",
    "\n",
    "    if actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['attack'])\n",
    "\n",
    "    if any('Build' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['build'])\n",
    "\n",
    "    if actions.FUNCTIONS.Harvest_Gather_screen.id in avail and any(u.unit_type == 341 for u in fus):\n",
    "        legal.append(ACTION_INDEX['gather'])\n",
    "\n",
    "    if any('Research' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['upgrade'])\n",
    "\n",
    "    if any('Train' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['train'])\n",
    "\n",
    "    return legal\n",
    "\n",
    "def make_pysc2_call(action_idx, ts, pending=None):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if pending:\n",
    "        if pending['action_fn'] in avail:\n",
    "            args = pending['args']\n",
    "            if len(args) > 1 and isinstance(args[1], list) and len(args[1]) == 2:\n",
    "                x, y = args[1]\n",
    "                return actions.FunctionCall(pending['action_fn'], [args[0], safe_coords(x, y)]), None\n",
    "            else:\n",
    "                return actions.FunctionCall(pending['action_fn'], args), None\n",
    "        else:\n",
    "            print(f\"[SKIP] Function {pending['action_fn']} not available anymore.\")\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    # ── Train: Select building first ──\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        building_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF and u.unit_type in TERRAN_STRUCTURE_TYPES]\n",
    "        if not building_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "        building = random.choice(building_units)\n",
    "        select_coords = safe_coords(building.x, building.y)\n",
    "        select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            next_action = {'action_fn': train_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "        return select_action, next_action\n",
    "\n",
    "    # ── Default: Select unit ──\n",
    "    selectable_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF]\n",
    "    if not selectable_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    unit = random.choice(selectable_units)\n",
    "    select_coords = safe_coords(unit.x, unit.y)\n",
    "    select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        next_action = {'action_fn': actions.FUNCTIONS.Move_screen.id, 'args': [[0], [x, y]]}\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Attack_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Harvest_Gather_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                next_action = {'action_fn': build_action, 'args': [[0], [x, y]]}\n",
    "            else:\n",
    "                next_action = None\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            next_action = {'action_fn': upgrade_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    else:\n",
    "        next_action = None\n",
    "\n",
    "    return select_action, next_action\n",
    "\n",
    "def make_pysc2_call_core(action_idx, ts):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if action_idx == ACTION_INDEX['do_nothing']:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.Move_screen.id, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Attack_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                return actions.FunctionCall(build_action, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Harvest_Gather_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            return actions.FunctionCall(upgrade_action, [[0]]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            return actions.FunctionCall(train_action, [[0]]), None\n",
    "\n",
    "    return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d4b4d6-c7fb-47f8-9b29-89ca20299c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f710a40-241f-4cef-91a8-4413a650d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pysc2.lib import actions\n",
    "from config import *\n",
    "# from utils import preprocess, legal_actions, make_pysc2_call\n",
    "\n",
    "\n",
    "def PPO(envs, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1.0, end_factor=0.0, total_iters=MAX_ITERS\n",
    "    )\n",
    "\n",
    "    ep_rewards = []\n",
    "\n",
    "    logger.info(\"▶️  Starting PPO for %d iterations\", MAX_ITERS)\n",
    "    for it in range(MAX_ITERS):\n",
    "        if it % 1000 == 0:\n",
    "            logger.info(\"🔄 Iter %d / %d\", it, MAX_ITERS)\n",
    "\n",
    "        # storage buffers\n",
    "        obs_buf  = torch.zeros(envs.nb, T, 2, SCREEN_SIZE, SCREEN_SIZE, device=DEVICE)\n",
    "        act_buf  = torch.zeros(envs.nb, T,      dtype=torch.long, device=DEVICE)\n",
    "        logp_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        val_buf  = torch.zeros(envs.nb, T+1,                   device=DEVICE)\n",
    "        rew_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        done_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        adv_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "\n",
    "        # ─── Rollout ─────────────────────────────────────────────────────────\n",
    "        with torch.no_grad():\n",
    "            for t in range(T):\n",
    "                for i in range(envs.nb):\n",
    "                    ts    = envs.obs[i]\n",
    "                    state = preprocess(ts)\n",
    "                    logits, value = model(state)\n",
    "\n",
    "                    # mask illegal\n",
    "                    LA   = legal_actions(ts)\n",
    "                    mask = torch.full_like(logits, float('-inf'))\n",
    "                    mask[0, LA] = 0.0\n",
    "                    dist = Categorical(logits=logits + mask)\n",
    "\n",
    "                    action = dist.sample()\n",
    "                    logp   = dist.log_prob(action)\n",
    "                    fc     = make_pysc2_call(action.item(), ts)\n",
    "\n",
    "                    # step (fallback to no-op)\n",
    "                    try:\n",
    "                        ts2 = envs.step(i, fc)\n",
    "                    except ValueError:\n",
    "                        ts2 = envs.step(i,\n",
    "                            actions.FunctionCall(actions.FUNCTIONS.no_op.id, []))\n",
    "\n",
    "                    # ── use env reward directly ─────────────────────────────\n",
    "                    r = ts2.reward\n",
    "                    d = float(ts2.last())\n",
    "\n",
    "                    obs_buf[i,t]  = state\n",
    "                    act_buf[i,t]  = action\n",
    "                    logp_buf[i,t] = logp\n",
    "                    val_buf[i,t]  = value\n",
    "                    rew_buf[i,t]  = r\n",
    "                    done_buf[i,t] = d\n",
    "\n",
    "                    if d:\n",
    "                        ep_rewards.append(sum(rew_buf[i, :t+1].tolist()))\n",
    "                        envs.reset(i)\n",
    "\n",
    "            # bootstrap final value\n",
    "            for i in range(envs.nb):\n",
    "                val_buf[i,T] = model(preprocess(envs.obs[i]))[1]\n",
    "\n",
    "        # ─── GAE & flatten ────────────────────────────────────────────────────\n",
    "        for i in range(envs.nb):\n",
    "            gae = 0\n",
    "            for t in reversed(range(T)):\n",
    "                mask  = 1.0 - done_buf[i,t]\n",
    "                delta = rew_buf[i,t] + GAMMA*val_buf[i,t+1]*mask - val_buf[i,t]\n",
    "                gae   = delta + GAMMA*GAE_LAMBDA*mask*gae\n",
    "                adv_buf[i,t] = gae\n",
    "\n",
    "        b_s  = obs_buf.reshape(-1,2,SCREEN_SIZE,SCREEN_SIZE)\n",
    "        b_a  = act_buf.reshape(-1)\n",
    "        b_lp = logp_buf.reshape(-1)\n",
    "        b_v  = val_buf[:,:T].reshape(-1)\n",
    "        b_ad = adv_buf.reshape(-1)\n",
    "\n",
    "        # ─── PPO updates ─────────────────────────────────────────────────────\n",
    "        for _ in range(K):\n",
    "            ds     = TensorDataset(b_s,b_a,b_lp,b_v,b_ad)\n",
    "            loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            for st, ac, old_lp, old_v, adv in loader:\n",
    "                logits, val = model(st)\n",
    "                dist        = Categorical(logits=logits)\n",
    "                lp          = dist.log_prob(ac)\n",
    "                ratio       = torch.exp(lp - old_lp)\n",
    "\n",
    "                clip   = 0.1 * (1 - it/MAX_ITERS)\n",
    "                obj1   = adv * ratio\n",
    "                obj2   = adv * torch.clamp(ratio, 1-clip, 1+clip)\n",
    "                p_loss = -torch.min(obj1,obj2).mean()\n",
    "\n",
    "                ret     = adv + old_v\n",
    "                v1      = (val - ret).pow(2)\n",
    "                v2      = (torch.clamp(val,old_v-clip,old_v+clip)-ret).pow(2)\n",
    "                v_loss  = 0.5 * torch.max(v1,v2).mean()\n",
    "\n",
    "                entropy = dist.entropy().mean()\n",
    "                loss    = p_loss + VF_COEF*v_loss - ENT_COEF*entropy\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(),0.5)\n",
    "                optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # ─── Plot learning curve ───────────────────────────────────────────────────\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(ep_rewards, label=\"episode reward\")\n",
    "    plt.title(\"Environment Reward per Episode\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"learning_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "    envs.close()\n",
    "    logger.info(\"✅ Training complete\")\n",
    "    logger.info(f\"Saved learning_curve.png over {len(ep_rewards)} episodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdcecead-f59c-4bbd-827d-771ad655c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d18d4c-cd99-477a-be83-74fd6005978b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from absl import app\n",
    "# # from environment import SC2Envs\n",
    "# # from model import ActorCritic\n",
    "# # from ppo import PPO\n",
    "# # from config import NB_ACTORS, DEVICE\n",
    "# # from utils import ACTION_LIST\n",
    "\n",
    "# def main(_):\n",
    "#     envs = SC2Envs(NB_ACTORS)\n",
    "#     model = ActorCritic(2, len(ACTION_LIST)).to(DEVICE)\n",
    "#     PPO(envs, model)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "#     sys.argv = sys.argv[:1]  # Remove extra flags passed by Jupyter or IPython\n",
    "#     app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942d6802-c091-4439-9f6c-a28b16ccbb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from rich.live import Live\n",
    "# from rich.table import Table\n",
    "# from rich.console import Console\n",
    "# from collections import deque\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import sys\n",
    "# from absl import flags\n",
    "\n",
    "# flags.FLAGS(sys.argv)  # fix required by pysc2\n",
    "# # from util import preprocess, legal_actions, make_pysc2_call\n",
    "# # from env import SC2Envs\n",
    "\n",
    "# console = Console()\n",
    "# envs = SC2Envs(nb_actor=1)\n",
    "# pending_action = [None] * envs.nb\n",
    "\n",
    "# MAX_ROWS = 20\n",
    "# recent_rows = deque(maxlen=MAX_ROWS)\n",
    "\n",
    "# # For tracking per-episode scores\n",
    "# episode_score = [0] * envs.nb\n",
    "# scores = []\n",
    "\n",
    "# def generate_table():\n",
    "#     table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "#     table.add_column(\"Step\", justify=\"right\")\n",
    "#     table.add_column(\"Function ID\", justify=\"right\")\n",
    "#     table.add_column(\"Args\", justify=\"left\")\n",
    "#     for row in recent_rows:\n",
    "#         table.add_row(*row)\n",
    "#     return table\n",
    "\n",
    "# with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "#     for step in range(MAX_ITERS):\n",
    "#         for i in range(envs.nb):\n",
    "#             ts = envs.obs[i]\n",
    "\n",
    "#             if pending_action[i]:\n",
    "#                 action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "#             else:\n",
    "#                 legal = legal_actions(ts)\n",
    "#                 action_idx = random.choice(legal)\n",
    "#                 action, pending_action[i] = make_pysc2_call(action_idx, ts)\n",
    "\n",
    "#             recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "#             live.update(generate_table())\n",
    "\n",
    "#             ts = envs.step(i, action)\n",
    "#             episode_score[i] += ts.reward\n",
    "\n",
    "#             if ts.last():\n",
    "#                 scores.append(episode_score[i])\n",
    "#                 episode_score[i] = 0  # reset\n",
    "#                 envs.reset(i)\n",
    "\n",
    "# envs.close()\n",
    "\n",
    "# # Plot episode scores\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(scores, label=\"Episode Score\", marker='o', linewidth=1.5)\n",
    "# plt.xlabel(\"Episode\")\n",
    "# plt.ylabel(\"Total Score\")\n",
    "# plt.title(\"Agent Score per Episode\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1044ec-ea4c-4ed4-91c4-6cede1bb862f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Campain Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3b570e-8f16-4ebf-ba44-aef48488f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         SC2 Agent Actions (Last 20 Steps)                                         </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">              Step </span>┃<span style=\"font-weight: bold\">                            Function ID </span>┃<span style=\"font-weight: bold\"> Args                                               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│              4980 │                                    331 │ [[0], [35, 73]]                                    │\n",
       "│              4981 │                                      2 │ [[0], ]                                            │\n",
       "│              4982 │                                      0 │ []                                                 │\n",
       "│              4983 │                                      2 │ [[0], ]                                            │\n",
       "│              4984 │                                      2 │ [[0], ]                                            │\n",
       "│              4985 │                                      2 │ [[0], ]                                            │\n",
       "│              4986 │                                      2 │ [[0], ]                                            │\n",
       "│              4987 │                                     79 │ [[0], ]                                            │\n",
       "│              4988 │                                      2 │ [[0], ]                                            │\n",
       "│              4989 │                                    331 │ [[0], [49, 83]]                                    │\n",
       "│              4990 │                                      2 │ [[0], ]                                            │\n",
       "│              4991 │                                      2 │ [[0], ]                                            │\n",
       "│              4992 │                                    477 │ [[0]]                                              │\n",
       "│              4993 │                                      2 │ [[0], ]                                            │\n",
       "│              4994 │                                      2 │ [[0], ]                                            │\n",
       "│              4995 │                                      2 │ [[0], ]                                            │\n",
       "│              4996 │                                      2 │ [[0], ]                                            │\n",
       "│              4997 │                                      2 │ [[0], ]                                            │\n",
       "│              4998 │                                      2 │ [[0], ]                                            │\n",
       "│              4999 │                                      2 │ [[0], ]                                            │\n",
       "└───────────────────┴────────────────────────────────────────┴────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         SC2 Agent Actions (Last 20 Steps)                                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m             Step\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                           Function ID\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mArgs                                              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│              4980 │                                    331 │ [[0], [35, 73]]                                    │\n",
       "│              4981 │                                      2 │ [[0], ]                                            │\n",
       "│              4982 │                                      0 │ []                                                 │\n",
       "│              4983 │                                      2 │ [[0], ]                                            │\n",
       "│              4984 │                                      2 │ [[0], ]                                            │\n",
       "│              4985 │                                      2 │ [[0], ]                                            │\n",
       "│              4986 │                                      2 │ [[0], ]                                            │\n",
       "│              4987 │                                     79 │ [[0], ]                                            │\n",
       "│              4988 │                                      2 │ [[0], ]                                            │\n",
       "│              4989 │                                    331 │ [[0], [49, 83]]                                    │\n",
       "│              4990 │                                      2 │ [[0], ]                                            │\n",
       "│              4991 │                                      2 │ [[0], ]                                            │\n",
       "│              4992 │                                    477 │ [[0]]                                              │\n",
       "│              4993 │                                      2 │ [[0], ]                                            │\n",
       "│              4994 │                                      2 │ [[0], ]                                            │\n",
       "│              4995 │                                      2 │ [[0], ]                                            │\n",
       "│              4996 │                                      2 │ [[0], ]                                            │\n",
       "│              4997 │                                      2 │ [[0], ]                                            │\n",
       "│              4998 │                                      2 │ [[0], ]                                            │\n",
       "│              4999 │                                      2 │ [[0], ]                                            │\n",
       "└───────────────────┴────────────────────────────────────────┴────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:06:44 [INFO] Environment Close\n",
      "15:06:44 [INFO] Shutdown gracefully.\n",
      "15:06:44 [INFO] Shutdown with return code: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "# Fix for absl.flags in Jupyter or script context\n",
    "flags.FLAGS(sys.argv, known_only=True)\n",
    "\n",
    "# Import your environment and utils\n",
    "# from util import preprocess, legal_actions, make_pysc2_call\n",
    "# from env import SC2EnvsMulti\n",
    "\n",
    "console = Console()\n",
    "envs = SC2EnvsMulti(nb_actor=1)\n",
    "pending_action = [None] * envs.nb\n",
    "\n",
    "MAX_ROWS = 20\n",
    "MAX_ITERS = 5000  # Set this to your desired number of steps\n",
    "recent_rows = deque(maxlen=MAX_ROWS)\n",
    "\n",
    "# For tracking per-episode scores\n",
    "episode_score = [0] * envs.nb\n",
    "scores = []\n",
    "\n",
    "def generate_table():\n",
    "    table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "    table.add_column(\"Step\", justify=\"right\")\n",
    "    table.add_column(\"Function ID\", justify=\"right\")\n",
    "    table.add_column(\"Args\", justify=\"left\")\n",
    "    for row in recent_rows:\n",
    "        table.add_row(*row)\n",
    "    return table\n",
    "\n",
    "# ─── Main Loop ───────────────────────────────────────────────────────────────\n",
    "with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "    for step in range(MAX_ITERS):\n",
    "        for i in range(envs.nb):\n",
    "            ts = envs.obs[i]\n",
    "\n",
    "            if pending_action[i]:\n",
    "                action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "            else:\n",
    "                legal = legal_actions(ts)\n",
    "                action_idx = random.choice(legal)\n",
    "                action, pending_action[i] = make_pysc2_call(action_idx, ts)\n",
    "\n",
    "            recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "            live.update(generate_table())\n",
    "\n",
    "            ts = envs.step(i, action)\n",
    "            episode_score[i] += ts.reward\n",
    "\n",
    "            if ts.last():\n",
    "                scores.append(episode_score[i])\n",
    "                episode_score[i] = 0  # reset\n",
    "                envs.reset(i)\n",
    "\n",
    "envs.close()\n",
    "\n",
    "# ─── Plot Episode Scores ─────────────────────────────────────────────────────\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(scores, label=\"Episode Score\", marker='o', linewidth=1.5)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Score\")\n",
    "plt.title(\"Agent Score per Episode\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50a927f7-75d7-4e23-b0f2-f2dc3997698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOad Replay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
