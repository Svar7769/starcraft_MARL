{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e76814-2083-496f-9cba-835f02a7fa47",
   "metadata": {},
   "source": [
    "# PPO- based Pysc2\n",
    "\n",
    "Modular Design\n",
    "sc2_ppo_project/\n",
    "\n",
    "â”œâ”€â”€ main.py             # Entry-point to run training\n",
    "\n",
    "â”œâ”€â”€ config.py           # Hyperparameters and logging config\n",
    "\n",
    "â”œâ”€â”€ environment.py      # SC2 environment wrapper\n",
    "\n",
    "â”œâ”€â”€ model.py            # Actor-Critic neural network\n",
    "\n",
    "â”œâ”€â”€ utils.py            # Observation preprocessing and action utilities\n",
    "\n",
    "â””â”€â”€ ppo.py              # PPO training algorithm implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f92e15-9658-4ec9-8e6c-2b6e7769257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9344929d-431d-4821-8768-35f16cb59ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# â”€â”€â”€ Hyperparameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MAP_NAME     = \"Simple64\"\n",
    "\n",
    "SCREEN_SIZE  = 84\n",
    "MINIMAP_SIZE = 64\n",
    "STEP_MUL     = 16\n",
    "NB_ACTORS    = 1\n",
    "T            = 128\n",
    "K            = 10\n",
    "BATCH_SIZE   = 256\n",
    "GAMMA        = 0.99\n",
    "GAE_LAMBDA   = 0.95\n",
    "LR           = 2.5e-4\n",
    "ENT_COEF     = 0.01\n",
    "VF_COEF      = 1.0\n",
    "MAX_ITERS    = 1000\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# â”€â”€â”€ Replay and Dataset Directories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "REPLAY_DIR   = os.path.join(\"replays\")             # Where to save .SC2Replay files\n",
    "DATASET_PATH = os.path.join(\"dataset.pkl\")         # Where to save (obs, action) dataset\n",
    "\n",
    "# â”€â”€â”€ Logging Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure replay directory exists\n",
    "os.makedirs(REPLAY_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c30bd3-1eff-4263-93d8-d42fc320ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656af9d7-6973-448b-b4f6-a6ca44b13d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pysc2.env import sc2_env\n",
    "# from pysc2.lib import actions, features\n",
    "# # from config import MAP_NAME, SCREEN_SIZE, MINIMAP_SIZE, STEP_MUL, logger\n",
    "\n",
    "# class SC2Envs:\n",
    "#     def __init__(self, nb_actor):\n",
    "#         logger.info(\"Initializing %d SC2 env(s)...\", nb_actor)\n",
    "#         self.nb   = nb_actor\n",
    "#         self.envs = [self._make_env() for _ in range(nb_actor)]\n",
    "#         self.obs  = [None]*nb_actor\n",
    "#         self.done = [False]*nb_actor\n",
    "#         self._init_all()\n",
    "#         logger.info(\"All SC2 env(s) ready.\")\n",
    "\n",
    "#     def _make_env(self):\n",
    "#         return sc2_env.SC2Env(\n",
    "#             map_name=MAP_NAME,\n",
    "#             players=[sc2_env.Agent(sc2_env.Race.terran)],\n",
    "#             agent_interface_format=features.AgentInterfaceFormat(\n",
    "#                 feature_dimensions=features.Dimensions(\n",
    "#                     screen=SCREEN_SIZE, minimap=MINIMAP_SIZE),\n",
    "#                 use_feature_units=True,\n",
    "#                 use_raw_units=False,\n",
    "#                 use_camera_position=True,\n",
    "#                 action_space=actions.ActionSpace.FEATURES\n",
    "#             ),\n",
    "#             step_mul=STEP_MUL,\n",
    "#             game_steps_per_episode=0,\n",
    "#             visualize=False,\n",
    "#         )\n",
    "\n",
    "#     def _init_all(self):\n",
    "#         for i, e in enumerate(self.envs):\n",
    "#             ts = e.reset()[0]\n",
    "#             self.obs[i], self.done[i] = ts, False\n",
    "\n",
    "#     def reset(self, i):\n",
    "#         ts = self.envs[i].reset()[0]\n",
    "#         self.obs[i], self.done[i] = ts, False\n",
    "#         return ts\n",
    "\n",
    "#     def step(self, i, fc):\n",
    "#         ts = self.envs[i].step([fc])[0]\n",
    "#         self.obs[i], self.done[i] = ts, ts.last()\n",
    "#         return ts\n",
    "\n",
    "#     def close(self):\n",
    "#         for e in self.envs:\n",
    "#             e.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009ecfc0-4629-46d1-9c03-55c6733f10f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SC2EnvsMulti:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nb_actor,\n",
    "        replay_dir=\"replays\",\n",
    "        replay_prefix=\"run\",\n",
    "        map_name=\"Simple64\",\n",
    "        screen_size=84,\n",
    "        minimap_size=64,\n",
    "        step_mul=16,\n",
    "    ):\n",
    "        self.nb = nb_actor\n",
    "\n",
    "        # â€” make replay_dir an absolute folder INSIDE YOUR PROJECT\n",
    "        self.replay_dir = os.path.join(os.getcwd(), replay_dir)\n",
    "        os.makedirs(self.replay_dir, exist_ok=True)\n",
    "\n",
    "        self.replay_prefix = replay_prefix\n",
    "\n",
    "        logger.info(\"Initializing %d SC2 env(s)â€¦\", self.nb)\n",
    "        self.envs = [\n",
    "            self._make_env(map_name, screen_size, minimap_size, step_mul)\n",
    "            for _ in range(self.nb)\n",
    "        ]\n",
    "        self.obs  = [env.reset()[0] for env in self.envs]\n",
    "        self.done = [False] * self.nb\n",
    "\n",
    "    def _make_env(self, map_name, screen_size, minimap_size, step_mul):\n",
    "        return sc2_env.SC2Env(\n",
    "            map_name=map_name,\n",
    "            players=[\n",
    "                sc2_env.Agent(sc2_env.Race.terran),\n",
    "                sc2_env.Bot(sc2_env.Race.terran, sc2_env.Difficulty.very_easy),\n",
    "            ],\n",
    "            agent_interface_format=features.AgentInterfaceFormat(\n",
    "                feature_dimensions=features.Dimensions(\n",
    "                    screen=screen_size, minimap=minimap_size\n",
    "                ),\n",
    "                use_feature_units=True,\n",
    "            ),\n",
    "            step_mul=step_mul,\n",
    "            visualize=False,\n",
    "\n",
    "            # â† now uses the absolute project path\n",
    "            save_replay_episodes=1,\n",
    "            replay_dir=self.replay_dir,\n",
    "            replay_prefix=self.replay_prefix,\n",
    "        )\n",
    "\n",
    "    def step(self, i, action):\n",
    "        ts = self.envs[i].step([action])[0]\n",
    "        self.obs[i]  = ts\n",
    "        self.done[i] = ts.last()\n",
    "        return ts\n",
    "\n",
    "    def reset(self, i):\n",
    "        self.obs[i]  = self.envs[i].reset()[0]\n",
    "        self.done[i] = False\n",
    "\n",
    "    def close(self):\n",
    "        for env in self.envs:\n",
    "            env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f776099f-7adf-49ec-b782-9b7d1f38d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d359419f-72a0-4747-aeec-d3cdb502bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from config import SCREEN_SIZE, DEVICE  # âœ… Import shared config\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, in_channels, nb_actions):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 8, stride=4), nn.Tanh(),\n",
    "            nn.Conv2d(16, 32, 4, stride=2), nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, SCREEN_SIZE, SCREEN_SIZE).to(DEVICE)\n",
    "            conv_out = self.conv(dummy).shape[-1]\n",
    "\n",
    "        self.fc     = nn.Sequential(nn.Linear(conv_out, 256), nn.Tanh())\n",
    "        self.actor  = nn.Linear(256, nb_actions)\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.fc(h)\n",
    "        return self.actor(h), self.critic(h).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70587f2-7223-4547-afe0-6a9f1c26f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28143d60-a430-4f01-829a-f1278b94f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from pysc2.lib import actions, features\n",
    "# # from config import DEVICE\n",
    "\n",
    "# _PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "# _UNIT_TYPE       = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "# ACTION_LIST = ['do_nothing', 'select_idle', 'build_refinery', 'harvest']\n",
    "# FUNC_ID = {\n",
    "#     'do_nothing': actions.FUNCTIONS.no_op.id,\n",
    "#     'select_idle': actions.FUNCTIONS.select_idle_worker.id,\n",
    "#     'build_refinery': actions.FUNCTIONS.Build_Refinery_screen.id,\n",
    "#     'harvest': actions.FUNCTIONS.Harvest_Gather_screen.id,\n",
    "# }\n",
    "\n",
    "# def preprocess(ts):\n",
    "#     fs = ts.observation.feature_screen\n",
    "#     pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "#     ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "#     stacked = np.stack([pr, ut], axis=0)\n",
    "#     return torch.from_numpy(stacked).unsqueeze(0).float().to(DEVICE)\n",
    "\n",
    "# def legal_actions(ts):\n",
    "#     avail = set(ts.observation.available_actions)\n",
    "#     fus   = ts.observation.feature_units\n",
    "#     legal = [0]\n",
    "#     if FUNC_ID['select_idle'] in avail: legal.append(1)\n",
    "#     if FUNC_ID['build_refinery'] in avail and any(u.unit_type==342 for u in fus): legal.append(2)\n",
    "#     if FUNC_ID['harvest'] in avail and any(u.unit_type==341 for u in fus): legal.append(3)\n",
    "#     return legal\n",
    "\n",
    "# def make_pysc2_call(action_idx, ts):\n",
    "#     name, fid = ACTION_LIST[action_idx], FUNC_ID[ACTION_LIST[action_idx]]\n",
    "#     if name == 'select_idle':\n",
    "#         return actions.FunctionCall(fid, [[2]])\n",
    "#     if name in ('build_refinery','harvest'):\n",
    "#         fus = ts.observation.feature_units\n",
    "#         cand = [u for u in fus if (u.unit_type==342 if name=='build_refinery' else u.unit_type==341)]\n",
    "#         if not cand:\n",
    "#             return actions.FunctionCall(actions.FUNCTIONS.no_op.id, [])\n",
    "#         u = random.choice(cand)\n",
    "#         return actions.FunctionCall(fid, [[0],[u.x,u.y]])\n",
    "#     return actions.FunctionCall(fid, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9259464-83a6-4c0d-a9a9-7b536dd1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pysc2.lib import actions, features\n",
    "\n",
    "_PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "_UNIT_TYPE = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "ACTION_LIST = ['do_nothing', 'move', 'attack', 'build', 'gather', 'upgrade', 'train']\n",
    "ACTION_INDEX = {name: idx for idx, name in enumerate(ACTION_LIST)}\n",
    "\n",
    "SCREEN_SIZE = 84\n",
    "\n",
    "# â”€â”€â”€ Terran Unit Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TERRAN_STRUCTURE_TYPES = [\n",
    "    18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30,\n",
    "    130, 131, 132, 133\n",
    "]\n",
    "\n",
    "# â”€â”€â”€ Enemy Tracking for Replay-Free Imitation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_enemy_units(ts):\n",
    "    return [\n",
    "        (u.unit_type, u.x, u.y, u.health)\n",
    "        for u in ts.observation.feature_units\n",
    "        if u.alliance == features.PlayerRelative.ENEMY\n",
    "    ]\n",
    "\n",
    "def infer_enemy_action(prev_units, curr_units):\n",
    "    if not prev_units or not curr_units:\n",
    "        return \"idle\"\n",
    "\n",
    "    for (ptype, x0, y0, hp0), (ptype2, x1, y1, hp1) in zip(prev_units, curr_units):\n",
    "        if ptype != ptype2:\n",
    "            continue\n",
    "        if x0 != x1 or y0 != y1:\n",
    "            return \"move\"\n",
    "        elif hp1 < hp0:\n",
    "            return \"attack\"\n",
    "    return \"idle\"\n",
    "\n",
    "# â”€â”€â”€ Observation Preprocessing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def safe_coords(x, y, screen_size=SCREEN_SIZE):\n",
    "    x = max(0, min(screen_size - 1, x))\n",
    "    y = max(0, min(screen_size - 1, y))\n",
    "    return [x, y]\n",
    "\n",
    "def preprocess(ts):\n",
    "    fs = ts.observation.feature_screen\n",
    "    pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "    ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "    stacked = np.stack([pr, ut], axis=0)\n",
    "    return torch.from_numpy(stacked).unsqueeze(0).float()\n",
    "\n",
    "# â”€â”€â”€ Legal Action Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def legal_actions(ts):\n",
    "    avail = set(ts.observation.available_actions)\n",
    "    fus = ts.observation.feature_units\n",
    "    legal = [ACTION_INDEX['do_nothing']]\n",
    "\n",
    "    if actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['move'])\n",
    "    if actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['attack'])\n",
    "    if any('Build' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['build'])\n",
    "    if actions.FUNCTIONS.Harvest_Gather_screen.id in avail and any(u.unit_type == 341 for u in fus):\n",
    "        legal.append(ACTION_INDEX['gather'])\n",
    "    if any('Research' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['upgrade'])\n",
    "    if any('Train' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['train'])\n",
    "\n",
    "    return legal\n",
    "\n",
    "# â”€â”€â”€ PySC2 Action Execution Wrapper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_pysc2_call(action_idx, ts, pending=None):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if pending:\n",
    "        if pending['action_fn'] in avail:\n",
    "            args = pending['args']\n",
    "            if len(args) > 1 and isinstance(args[1], list) and len(args[1]) == 2:\n",
    "                x, y = args[1]\n",
    "                return actions.FunctionCall(pending['action_fn'], [args[0], safe_coords(x, y)]), None\n",
    "            else:\n",
    "                return actions.FunctionCall(pending['action_fn'], args), None\n",
    "        else:\n",
    "            print(f\"[SKIP] Function {pending['action_fn']} not available anymore.\")\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        building_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF and u.unit_type in TERRAN_STRUCTURE_TYPES]\n",
    "        if not building_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "        building = random.choice(building_units)\n",
    "        select_coords = safe_coords(building.x, building.y)\n",
    "        select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            next_action = {'action_fn': train_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "        return select_action, next_action\n",
    "\n",
    "    selectable_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF]\n",
    "    if not selectable_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    unit = random.choice(selectable_units)\n",
    "    select_coords = safe_coords(unit.x, unit.y)\n",
    "    select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        next_action = {'action_fn': actions.FUNCTIONS.Move_screen.id, 'args': [[0], [x, y]]}\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Attack_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Harvest_Gather_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                next_action = {'action_fn': build_action, 'args': [[0], [x, y]]}\n",
    "            else:\n",
    "                next_action = None\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            next_action = {'action_fn': upgrade_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    else:\n",
    "        next_action = None\n",
    "\n",
    "    return select_action, next_action\n",
    "\n",
    "# â”€â”€â”€ Core Call (No Select Chain) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_pysc2_call_core(action_idx, ts):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if action_idx == ACTION_INDEX['do_nothing']:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.Move_screen.id, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Attack_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                return actions.FunctionCall(build_action, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Harvest_Gather_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            return actions.FunctionCall(upgrade_action, [[0]]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            return actions.FunctionCall(train_action, [[0]]), None\n",
    "\n",
    "    return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d4b4d6-c7fb-47f8-9b29-89ca20299c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f710a40-241f-4cef-91a8-4413a650d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from pysc2.lib import actions\n",
    "from config import *\n",
    "# from utils import preprocess, legal_actions, make_pysc2_call, extract_enemy_units, infer_enemy_action\n",
    "\n",
    "def PPO(envs, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1.0, end_factor=0.0, total_iters=MAX_ITERS\n",
    "    )\n",
    "\n",
    "    ep_rewards = []\n",
    "    expert_dataset = []  # Collect enemy bot data\n",
    "\n",
    "    logger.info(\"â–¶ï¸  Starting PPO for %d iterations\", MAX_ITERS)\n",
    "    for it in range(MAX_ITERS):\n",
    "        if it % 1000 == 0:\n",
    "            logger.info(\"ğŸ”„ Iter %d / %d\", it, MAX_ITERS)\n",
    "\n",
    "        # storage buffers\n",
    "        obs_buf  = torch.zeros(envs.nb, T, 2, SCREEN_SIZE, SCREEN_SIZE, device=DEVICE)\n",
    "        act_buf  = torch.zeros(envs.nb, T,      dtype=torch.long, device=DEVICE)\n",
    "        logp_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        val_buf  = torch.zeros(envs.nb, T+1,                   device=DEVICE)\n",
    "        rew_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        done_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        adv_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "\n",
    "        # â”€â”€â”€ Rollout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        with torch.no_grad():\n",
    "            for t in range(T):\n",
    "                for i in range(envs.nb):\n",
    "                    ts    = envs.obs[i]\n",
    "                    state = preprocess(ts)\n",
    "                    logits, value = model(state)\n",
    "\n",
    "                    # mask illegal\n",
    "                    LA   = legal_actions(ts)\n",
    "                    mask = torch.full_like(logits, float('-inf'))\n",
    "                    mask[0, LA] = 0.0\n",
    "                    dist = Categorical(logits=logits + mask)\n",
    "\n",
    "                    action = dist.sample()\n",
    "                    logp   = dist.log_prob(action)\n",
    "                    fc     = make_pysc2_call(action.item(), ts)\n",
    "\n",
    "                    # step (fallback to no-op)\n",
    "                    try:\n",
    "                        ts2 = envs.step(i, fc)\n",
    "                    except ValueError:\n",
    "                        ts2 = envs.step(i, actions.FunctionCall(actions.FUNCTIONS.no_op.id, []))\n",
    "\n",
    "                    r = ts2.reward\n",
    "                    d = float(ts2.last())\n",
    "\n",
    "                    obs_buf[i,t]  = state\n",
    "                    act_buf[i,t]  = action\n",
    "                    logp_buf[i,t] = logp\n",
    "                    val_buf[i,t]  = value\n",
    "                    rew_buf[i,t]  = r\n",
    "                    done_buf[i,t] = d\n",
    "\n",
    "                    if d:\n",
    "                        ep_rewards.append(sum(rew_buf[i, :t+1].tolist()))\n",
    "                        envs.reset(i)\n",
    "\n",
    "            for i in range(envs.nb):\n",
    "                val_buf[i,T] = model(preprocess(envs.obs[i]))[1]\n",
    "\n",
    "        # â”€â”€â”€ GAE & flatten â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for i in range(envs.nb):\n",
    "            gae = 0\n",
    "            for t in reversed(range(T)):\n",
    "                mask  = 1.0 - done_buf[i,t]\n",
    "                delta = rew_buf[i,t] + GAMMA*val_buf[i,t+1]*mask - val_buf[i,t]\n",
    "                gae   = delta + GAMMA*GAE_LAMBDA*mask*gae\n",
    "                adv_buf[i,t] = gae\n",
    "\n",
    "        b_s  = obs_buf.reshape(-1,2,SCREEN_SIZE,SCREEN_SIZE)\n",
    "        b_a  = act_buf.reshape(-1)\n",
    "        b_lp = logp_buf.reshape(-1)\n",
    "        b_v  = val_buf[:,:T].reshape(-1)\n",
    "        b_ad = adv_buf.reshape(-1)\n",
    "\n",
    "        # â”€â”€â”€ PPO updates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for _ in range(K):\n",
    "            ds     = TensorDataset(b_s,b_a,b_lp,b_v,b_ad)\n",
    "            loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            for st, ac, old_lp, old_v, adv in loader:\n",
    "                logits, val = model(st)\n",
    "                dist        = Categorical(logits=logits)\n",
    "                lp          = dist.log_prob(ac)\n",
    "                ratio       = torch.exp(lp - old_lp)\n",
    "\n",
    "                clip   = 0.1 * (1 - it/MAX_ITERS)\n",
    "                obj1   = adv * ratio\n",
    "                obj2   = adv * torch.clamp(ratio, 1-clip, 1+clip)\n",
    "                p_loss = -torch.min(obj1,obj2).mean()\n",
    "\n",
    "                ret     = adv + old_v\n",
    "                v1      = (val - ret).pow(2)\n",
    "                v2      = (torch.clamp(val,old_v-clip,old_v+clip)-ret).pow(2)\n",
    "                v_loss  = 0.5 * torch.max(v1,v2).mean()\n",
    "\n",
    "                entropy = dist.entropy().mean()\n",
    "                loss    = p_loss + VF_COEF*v_loss - ENT_COEF*entropy\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(),0.5)\n",
    "                optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # â”€â”€â”€ Save replays only at end â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for i in range(envs.nb):\n",
    "        replay_path = os.path.join(REPLAY_DIR, f\"ppo_final_{i}.SC2Replay\")\n",
    "        envs.envs[i]._save_replay(\"PPO\", replay_path)\n",
    "    logger.info(\"ğŸ’¾ Saved final replay(s) to %s\", REPLAY_DIR)\n",
    "\n",
    "    # â”€â”€â”€ Plot learning curve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(ep_rewards, label=\"episode reward\")\n",
    "    plt.title(\"Environment Reward per Episode\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"learning_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "    envs.close()\n",
    "    logger.info(\"âœ… Training complete\")\n",
    "    logger.info(f\"Saved learning_curve.png over {len(ep_rewards)} episodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdcecead-f59c-4bbd-827d-771ad655c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d18d4c-cd99-477a-be83-74fd6005978b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from absl import app\n",
    "# # from environment import SC2Envs\n",
    "# # from model import ActorCritic\n",
    "# # from ppo import PPO\n",
    "# # from config import NB_ACTORS, DEVICE\n",
    "# # from utils import ACTION_LIST\n",
    "\n",
    "# def main(_):\n",
    "#     envs = SC2Envs(NB_ACTORS)\n",
    "#     model = ActorCritic(2, len(ACTION_LIST)).to(DEVICE)\n",
    "#     PPO(envs, model)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "#     sys.argv = sys.argv[:1]  # Remove extra flags passed by Jupyter or IPython\n",
    "#     app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "942d6802-c091-4439-9f6c-a28b16ccbb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from rich.live import Live\n",
    "# from rich.table import Table\n",
    "# from rich.console import Console\n",
    "# from collections import deque\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import sys\n",
    "# from absl import flags\n",
    "\n",
    "# flags.FLAGS(sys.argv)  # fix required by pysc2\n",
    "# # from util import preprocess, legal_actions, make_pysc2_call\n",
    "# # from env import SC2Envs\n",
    "\n",
    "# console = Console()\n",
    "# envs = SC2Envs(nb_actor=1)\n",
    "# pending_action = [None] * envs.nb\n",
    "\n",
    "# MAX_ROWS = 20\n",
    "# recent_rows = deque(maxlen=MAX_ROWS)\n",
    "\n",
    "# # For tracking per-episode scores\n",
    "# episode_score = [0] * envs.nb\n",
    "# scores = []\n",
    "\n",
    "# def generate_table():\n",
    "#     table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "#     table.add_column(\"Step\", justify=\"right\")\n",
    "#     table.add_column(\"Function ID\", justify=\"right\")\n",
    "#     table.add_column(\"Args\", justify=\"left\")\n",
    "#     for row in recent_rows:\n",
    "#         table.add_row(*row)\n",
    "#     return table\n",
    "\n",
    "# with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "#     for step in range(MAX_ITERS):\n",
    "#         for i in range(envs.nb):\n",
    "#             ts = envs.obs[i]\n",
    "\n",
    "#             if pending_action[i]:\n",
    "#                 action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "#             else:\n",
    "#                 legal = legal_actions(ts)\n",
    "#                 action_idx = random.choice(legal)\n",
    "#                 action, pending_action[i] = make_pysc2_call(action_idx, ts)\n",
    "\n",
    "#             recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "#             live.update(generate_table())\n",
    "\n",
    "#             ts = envs.step(i, action)\n",
    "#             episode_score[i] += ts.reward\n",
    "\n",
    "#             if ts.last():\n",
    "#                 scores.append(episode_score[i])\n",
    "#                 episode_score[i] = 0  # reset\n",
    "#                 envs.reset(i)\n",
    "\n",
    "# envs.close()\n",
    "\n",
    "# # Plot episode scores\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.plot(scores, label=\"Episode Score\", marker='o', linewidth=1.5)\n",
    "# plt.xlabel(\"Episode\")\n",
    "# plt.ylabel(\"Total Score\")\n",
    "# plt.title(\"Agent Score per Episode\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1044ec-ea4c-4ed4-91c4-6cede1bb862f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Campain Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b570e-8f16-4ebf-ba44-aef48488f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         SC2 Agent Actions (Last 20 Steps)                                         </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">              Step </span>â”ƒ<span style=\"font-weight: bold\">                            Function ID </span>â”ƒ<span style=\"font-weight: bold\"> Args                                               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚               374 â”‚                                    331 â”‚ [[0], [59, 69]]                                    â”‚\n",
       "â”‚               374 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               375 â”‚                                    264 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         SC2 Agent Actions (Last 20 Steps)                                         \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m             Step\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                           Function ID\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mArgs                                              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚               374 â”‚                                    331 â”‚ [[0], [59, 69]]                                    â”‚\n",
       "â”‚               374 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               375 â”‚                                    264 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               375 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               376 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚               376 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               377 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚               378 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "import matplotlib.pyplot as plt\n",
    "from absl import flags\n",
    "\n",
    "# from environment import SC2EnvsMulti\n",
    "# from utils import make_pysc2_call, legal_actions  # your existing helpers\n",
    "\n",
    "# Fix for absl.flags in script context\n",
    "flags.FLAGS(sys.argv, known_only=True)\n",
    "\n",
    "# â”€â”€â”€ Settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NUM_EPISODES  = 20\n",
    "NB_ACTORS     = 5\n",
    "REPLAY_DIR    = \"replays\"\n",
    "REPLAY_PREFIX = \"pysc2_run\"\n",
    "\n",
    "console = Console()\n",
    "envs = SC2EnvsMulti(\n",
    "    nb_actor=NB_ACTORS,\n",
    "    replay_dir=REPLAY_DIR,\n",
    "    replay_prefix=REPLAY_PREFIX,\n",
    ")\n",
    "\n",
    "pending_action = [None] * envs.nb\n",
    "MAX_ROWS    = 20\n",
    "recent_rows = deque(maxlen=MAX_ROWS)\n",
    "scores      = []\n",
    "\n",
    "def generate_table():\n",
    "    table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "    table.add_column(\"Step\", justify=\"right\")\n",
    "    table.add_column(\"Function ID\", justify=\"right\")\n",
    "    table.add_column(\"Args\", justify=\"left\")\n",
    "    for row in recent_rows:\n",
    "        table.add_row(*row)\n",
    "    return table\n",
    "\n",
    "# â”€â”€â”€ Episode Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "    for ep in range(1, NUM_EPISODES + 1):\n",
    "        # reset each parallel env\n",
    "        for i in range(envs.nb):\n",
    "            envs.reset(i)\n",
    "        episode_score = [0] * envs.nb\n",
    "\n",
    "        console.log(f\"[blue]=== Episode {ep} ===[/blue]\")\n",
    "        step = 0\n",
    "\n",
    "        while True:\n",
    "            for i in range(envs.nb):\n",
    "                ts = envs.obs[i]\n",
    "\n",
    "                if pending_action[i]:\n",
    "                    action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "                else:\n",
    "                    legal  = legal_actions(ts)\n",
    "                    choice = random.choice(legal)\n",
    "                    action, pending_action[i] = make_pysc2_call(choice, ts)\n",
    "\n",
    "                recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "                live.update(generate_table())\n",
    "\n",
    "                ts = envs.step(i, action)\n",
    "                episode_score[i] += ts.reward\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if any(envs.done):\n",
    "                console.log(f\"[green]Episode {ep} done, score: {episode_score}[/green]\")\n",
    "                scores.extend(episode_score)\n",
    "                break\n",
    "\n",
    "# â”€â”€â”€ Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "envs.close()\n",
    "\n",
    "# â”€â”€â”€ Plot Episode Scores â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(scores, label=\"Episode Score\", marker=\"o\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Score\")\n",
    "plt.title(\"Agent Score per Episode\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87a1e3-1c57-41da-a461-9c6a4a0b6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "\n",
    "def main():\n",
    "    # Make an absolute folder INSIDE YOUR PROJECT\n",
    "    PROJECT_REPLAY_DIR = os.path.join(os.getcwd(), \"replays\")\n",
    "    os.makedirs(PROJECT_REPLAY_DIR, exist_ok=True)\n",
    "\n",
    "    with sc2_env.SC2Env(\n",
    "        map_name=\"Simple64\",\n",
    "        players=[\n",
    "            sc2_env.Agent(sc2_env.Race.terran),\n",
    "            sc2_env.Bot(sc2_env.Race.terran, sc2_env.Difficulty.very_easy),\n",
    "        ],\n",
    "        agent_interface_format=features.AgentInterfaceFormat(\n",
    "            feature_dimensions=features.Dimensions(screen=84, minimap=64),\n",
    "            use_feature_units=True,\n",
    "        ),\n",
    "        step_mul=8,\n",
    "        visualize=False,\n",
    "\n",
    "        save_replay_episodes=1,\n",
    "        # â† NOW AN ABSOLUTE PATH\n",
    "        replay_dir=PROJECT_REPLAY_DIR,\n",
    "        replay_prefix=\"pysc2_run\",\n",
    "    ) as env:\n",
    "        for ep in range(1, 2):\n",
    "            print(f\"=== Episode {ep} ===\")\n",
    "            timesteps = env.reset()\n",
    "            total_reward = 0.0\n",
    "            while True:\n",
    "                # noâ€op is always valid\n",
    "                action = actions.FUNCTIONS.no_op()\n",
    "                timesteps = env.step([action])\n",
    "                total_reward += timesteps[0].reward\n",
    "                if timesteps[0].last():\n",
    "                    print(f\"Episode {ep} ended, reward = {total_reward}\")\n",
    "                    break\n",
    "\n",
    "    print(f\"Replays are in {PROJECT_REPLAY_DIR}/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4204dc52-7157-4d41-9c48-52bba64e0baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202095a-e051-4db0-8711-0b827819118a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
