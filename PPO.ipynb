{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e76814-2083-496f-9cba-835f02a7fa47",
   "metadata": {},
   "source": [
    "# PPO- based Pysc2\n",
    "\n",
    "Modular Design\n",
    "sc2_ppo_project/\n",
    "\n",
    "â”œâ”€â”€ main.py             # Entry-point to run training\n",
    "\n",
    "â”œâ”€â”€ config.py           # Hyperparameters and logging config\n",
    "\n",
    "â”œâ”€â”€ environment.py      # SC2 environment wrapper\n",
    "\n",
    "â”œâ”€â”€ model.py            # Actor-Critic neural network\n",
    "\n",
    "â”œâ”€â”€ utils.py            # Observation preprocessing and action utilities\n",
    "\n",
    "â””â”€â”€ ppo.py              # PPO training algorithm implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f92e15-9658-4ec9-8e6c-2b6e7769257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9344929d-431d-4821-8768-35f16cb59ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "# â”€â”€â”€ Hyperparameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MAP_NAME     = \"CollectMineralsAndGas\"\n",
    "MAP_NAME     = \"Simple64\"\n",
    "\n",
    "SCREEN_SIZE  = 84\n",
    "MINIMAP_SIZE = 64\n",
    "STEP_MUL     = 16\n",
    "NB_ACTORS    = 1\n",
    "T            = 128\n",
    "K            = 10\n",
    "BATCH_SIZE   = 256\n",
    "GAMMA        = 0.99\n",
    "GAE_LAMBDA   = 0.95\n",
    "LR           = 2.5e-4\n",
    "ENT_COEF     = 0.01\n",
    "VF_COEF      = 1.0\n",
    "MAX_ITERS    = 10000\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# â”€â”€â”€ Logging Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25c30bd3-1eff-4263-93d8-d42fc320ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "656af9d7-6973-448b-b4f6-a6ca44b13d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "# from config import MAP_NAME, SCREEN_SIZE, MINIMAP_SIZE, STEP_MUL, logger\n",
    "\n",
    "class SC2Envs:\n",
    "    def __init__(self, nb_actor):\n",
    "        logger.info(\"Initializing %d SC2 env(s)...\", nb_actor)\n",
    "        self.nb   = nb_actor\n",
    "        self.envs = [self._make_env() for _ in range(nb_actor)]\n",
    "        self.obs  = [None]*nb_actor\n",
    "        self.done = [False]*nb_actor\n",
    "        self._init_all()\n",
    "        logger.info(\"All SC2 env(s) ready.\")\n",
    "\n",
    "    def _make_env(self):\n",
    "        return sc2_env.SC2Env(\n",
    "            map_name=MAP_NAME,\n",
    "            players=[sc2_env.Agent(sc2_env.Race.terran)],\n",
    "            agent_interface_format=features.AgentInterfaceFormat(\n",
    "                feature_dimensions=features.Dimensions(\n",
    "                    screen=SCREEN_SIZE, minimap=MINIMAP_SIZE),\n",
    "                use_feature_units=True,\n",
    "                use_raw_units=False,\n",
    "                use_camera_position=True,\n",
    "                action_space=actions.ActionSpace.FEATURES\n",
    "            ),\n",
    "            step_mul=STEP_MUL,\n",
    "            game_steps_per_episode=0,\n",
    "            visualize=False,\n",
    "        )\n",
    "\n",
    "    def _init_all(self):\n",
    "        for i, e in enumerate(self.envs):\n",
    "            ts = e.reset()[0]\n",
    "            self.obs[i], self.done[i] = ts, False\n",
    "\n",
    "    def reset(self, i):\n",
    "        ts = self.envs[i].reset()[0]\n",
    "        self.obs[i], self.done[i] = ts, False\n",
    "        return ts\n",
    "\n",
    "    def step(self, i, fc):\n",
    "        ts = self.envs[i].step([fc])[0]\n",
    "        self.obs[i], self.done[i] = ts, ts.last()\n",
    "        return ts\n",
    "\n",
    "    def close(self):\n",
    "        for e in self.envs:\n",
    "            e.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "009ecfc0-4629-46d1-9c03-55c6733f10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi Plaer Map\n",
    "\n",
    "from pysc2.env import sc2_env\n",
    "from pysc2.lib import actions, features\n",
    "import logging\n",
    "\n",
    "class SC2EnvsMulti:\n",
    "    def __init__(self, nb_actor):\n",
    "        logger.info(\"Initializing %d SC2 env(s)...\", nb_actor)\n",
    "        self.nb = nb_actor\n",
    "        self.envs = [self._make_env() for _ in range(nb_actor)]\n",
    "        self.obs = [env.reset()[0] for env in self.envs]\n",
    "        self.done = [False] * nb_actor\n",
    "\n",
    "    def _make_env(self):\n",
    "        return sc2_env.SC2Env(\n",
    "            map_name=MAP_NAME,\n",
    "            players=[\n",
    "                sc2_env.Agent(sc2_env.Race.terran),\n",
    "                sc2_env.Bot(sc2_env.Race.terran, sc2_env.Difficulty.very_easy)\n",
    "\n",
    "            ],\n",
    "            agent_interface_format=features.AgentInterfaceFormat(\n",
    "                feature_dimensions=features.Dimensions(\n",
    "                    screen=SCREEN_SIZE, minimap=MINIMAP_SIZE),\n",
    "                use_feature_units=True,\n",
    "                use_raw_units=False,\n",
    "                use_camera_position=True,\n",
    "                action_space=actions.ActionSpace.FEATURES\n",
    "            ),\n",
    "            step_mul=STEP_MUL,\n",
    "            game_steps_per_episode=0,\n",
    "            visualize=False\n",
    "        )\n",
    "\n",
    "    def step(self, i, action):\n",
    "        timestep = self.envs[i].step([action])[0]\n",
    "        self.obs[i] = timestep\n",
    "        self.done[i] = timestep.last()\n",
    "        return timestep\n",
    "\n",
    "    def reset(self, i):\n",
    "        self.obs[i] = self.envs[i].reset()[0]\n",
    "        self.done[i] = False\n",
    "\n",
    "    def close(self):\n",
    "        for env in self.envs:\n",
    "            env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f776099f-7adf-49ec-b782-9b7d1f38d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d359419f-72a0-4747-aeec-d3cdb502bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from config import SCREEN_SIZE, DEVICE\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, in_channels, nb_actions):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 8, stride=4), nn.Tanh(),\n",
    "            nn.Conv2d(16, 32, 4, stride=2), nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, in_channels, SCREEN_SIZE, SCREEN_SIZE)\n",
    "            conv_out = self.conv(dummy).shape[-1]\n",
    "\n",
    "        self.fc     = nn.Sequential(nn.Linear(conv_out, 256), nn.Tanh())\n",
    "        self.actor  = nn.Linear(256, nb_actions)\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = self.fc(h)\n",
    "        return self.actor(h), self.critic(h).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c70587f2-7223-4547-afe0-6a9f1c26f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28143d60-a430-4f01-829a-f1278b94f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from pysc2.lib import actions, features\n",
    "# # from config import DEVICE\n",
    "\n",
    "# _PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "# _UNIT_TYPE       = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "# ACTION_LIST = ['do_nothing', 'select_idle', 'build_refinery', 'harvest']\n",
    "# FUNC_ID = {\n",
    "#     'do_nothing': actions.FUNCTIONS.no_op.id,\n",
    "#     'select_idle': actions.FUNCTIONS.select_idle_worker.id,\n",
    "#     'build_refinery': actions.FUNCTIONS.Build_Refinery_screen.id,\n",
    "#     'harvest': actions.FUNCTIONS.Harvest_Gather_screen.id,\n",
    "# }\n",
    "\n",
    "# def preprocess(ts):\n",
    "#     fs = ts.observation.feature_screen\n",
    "#     pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "#     ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "#     stacked = np.stack([pr, ut], axis=0)\n",
    "#     return torch.from_numpy(stacked).unsqueeze(0).float().to(DEVICE)\n",
    "\n",
    "# def legal_actions(ts):\n",
    "#     avail = set(ts.observation.available_actions)\n",
    "#     fus   = ts.observation.feature_units\n",
    "#     legal = [0]\n",
    "#     if FUNC_ID['select_idle'] in avail: legal.append(1)\n",
    "#     if FUNC_ID['build_refinery'] in avail and any(u.unit_type==342 for u in fus): legal.append(2)\n",
    "#     if FUNC_ID['harvest'] in avail and any(u.unit_type==341 for u in fus): legal.append(3)\n",
    "#     return legal\n",
    "\n",
    "# def make_pysc2_call(action_idx, ts):\n",
    "#     name, fid = ACTION_LIST[action_idx], FUNC_ID[ACTION_LIST[action_idx]]\n",
    "#     if name == 'select_idle':\n",
    "#         return actions.FunctionCall(fid, [[2]])\n",
    "#     if name in ('build_refinery','harvest'):\n",
    "#         fus = ts.observation.feature_units\n",
    "#         cand = [u for u in fus if (u.unit_type==342 if name=='build_refinery' else u.unit_type==341)]\n",
    "#         if not cand:\n",
    "#             return actions.FunctionCall(actions.FUNCTIONS.no_op.id, [])\n",
    "#         u = random.choice(cand)\n",
    "#         return actions.FunctionCall(fid, [[0],[u.x,u.y]])\n",
    "#     return actions.FunctionCall(fid, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9259464-83a6-4c0d-a9a9-7b536dd1af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pysc2.lib import actions, features\n",
    "\n",
    "_PLAYER_RELATIVE = features.SCREEN_FEATURES.player_relative.index\n",
    "_UNIT_TYPE = features.SCREEN_FEATURES.unit_type.index\n",
    "\n",
    "ACTION_LIST = ['do_nothing', 'move', 'attack', 'build', 'gather', 'upgrade', 'train']\n",
    "ACTION_INDEX = {name: idx for idx, name in enumerate(ACTION_LIST)}\n",
    "\n",
    "SCREEN_SIZE = 84\n",
    "\n",
    "# Terran building unit_type IDs (partial list â€” expand as needed)\n",
    "TERRAN_STRUCTURE_TYPES = [\n",
    "    18,   # CommandCenter\n",
    "    20,   # SupplyDepot\n",
    "    21,   # Barracks\n",
    "    22,   # EngineeringBay\n",
    "    23,   # MissileTurret\n",
    "    24,   # Bunker\n",
    "    25,   # Refinery\n",
    "    27,   # Factory\n",
    "    28,   # GhostAcademy\n",
    "    29,   # Starport\n",
    "    30,   # Armory\n",
    "    130, 131, 132, 133  # Tech lab, Reactor, etc.\n",
    "]\n",
    "\n",
    "def safe_coords(x, y, screen_size=SCREEN_SIZE):\n",
    "    x = max(0, min(screen_size - 1, x))\n",
    "    y = max(0, min(screen_size - 1, y))\n",
    "    return [x, y]\n",
    "\n",
    "def preprocess(ts):\n",
    "    fs = ts.observation.feature_screen\n",
    "    pr = fs[_PLAYER_RELATIVE].astype(np.float32) / 4.0\n",
    "    ut = fs[_UNIT_TYPE].astype(np.float32) / fs[_UNIT_TYPE].max()\n",
    "    stacked = np.stack([pr, ut], axis=0)\n",
    "    return torch.from_numpy(stacked).unsqueeze(0).float()\n",
    "\n",
    "def legal_actions(ts):\n",
    "    avail = set(ts.observation.available_actions)\n",
    "    fus = ts.observation.feature_units\n",
    "    legal = [ACTION_INDEX['do_nothing']]\n",
    "\n",
    "    if actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['move'])\n",
    "\n",
    "    if actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        legal.append(ACTION_INDEX['attack'])\n",
    "\n",
    "    if any('Build' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['build'])\n",
    "\n",
    "    if actions.FUNCTIONS.Harvest_Gather_screen.id in avail and any(u.unit_type == 341 for u in fus):\n",
    "        legal.append(ACTION_INDEX['gather'])\n",
    "\n",
    "    if any('Research' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['upgrade'])\n",
    "\n",
    "    if any('Train' in actions.FUNCTIONS[a].name for a in avail):\n",
    "        legal.append(ACTION_INDEX['train'])\n",
    "\n",
    "    return legal\n",
    "\n",
    "def make_pysc2_call(action_idx, ts, pending=None):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if pending:\n",
    "        if pending['action_fn'] in avail:\n",
    "            args = pending['args']\n",
    "            if len(args) > 1 and isinstance(args[1], list) and len(args[1]) == 2:\n",
    "                x, y = args[1]\n",
    "                return actions.FunctionCall(pending['action_fn'], [args[0], safe_coords(x, y)]), None\n",
    "            else:\n",
    "                return actions.FunctionCall(pending['action_fn'], args), None\n",
    "        else:\n",
    "            print(f\"[SKIP] Function {pending['action_fn']} not available anymore.\")\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    # â”€â”€ Train: Select building first â”€â”€\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        building_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF and u.unit_type in TERRAN_STRUCTURE_TYPES]\n",
    "        if not building_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "        building = random.choice(building_units)\n",
    "        select_coords = safe_coords(building.x, building.y)\n",
    "        select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            next_action = {'action_fn': train_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "        return select_action, next_action\n",
    "\n",
    "    # â”€â”€ Default: Select unit â”€â”€\n",
    "    selectable_units = [u for u in fus if u.alliance == features.PlayerRelative.SELF]\n",
    "    if not selectable_units or actions.FUNCTIONS.select_point.id not in avail:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    unit = random.choice(selectable_units)\n",
    "    select_coords = safe_coords(unit.x, unit.y)\n",
    "    select_action = actions.FunctionCall(actions.FUNCTIONS.select_point.id, [[0], select_coords])\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        next_action = {'action_fn': actions.FUNCTIONS.Move_screen.id, 'args': [[0], [x, y]]}\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Attack_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            next_action = {'action_fn': actions.FUNCTIONS.Harvest_Gather_screen.id, 'args': [[0], [target.x, target.y]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                next_action = {'action_fn': build_action, 'args': [[0], [x, y]]}\n",
    "            else:\n",
    "                next_action = None\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    elif action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            next_action = {'action_fn': upgrade_action, 'args': [[0]]}\n",
    "        else:\n",
    "            next_action = None\n",
    "\n",
    "    else:\n",
    "        next_action = None\n",
    "\n",
    "    return select_action, next_action\n",
    "\n",
    "def make_pysc2_call_core(action_idx, ts):\n",
    "    obs = ts.observation\n",
    "    fus = obs.feature_units\n",
    "    avail = set(obs.available_actions)\n",
    "\n",
    "    if action_idx == ACTION_INDEX['do_nothing']:\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['move'] and actions.FUNCTIONS.Move_screen.id in avail:\n",
    "        x, y = np.random.randint(0, SCREEN_SIZE), np.random.randint(0, SCREEN_SIZE)\n",
    "        return actions.FunctionCall(actions.FUNCTIONS.Move_screen.id, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['attack'] and actions.FUNCTIONS.Attack_screen.id in avail:\n",
    "        enemies = [u for u in fus if u.alliance == features.PlayerRelative.ENEMY]\n",
    "        if enemies:\n",
    "            target = random.choice(enemies)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Attack_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['build']:\n",
    "        build_actions = [a for a in avail if 'Build' in actions.FUNCTIONS[a].name]\n",
    "        if build_actions:\n",
    "            build_action = random.choice(build_actions)\n",
    "            buildable = np.argwhere(obs.feature_screen.buildable == 1)\n",
    "            if buildable.size > 0:\n",
    "                y, x = random.choice(buildable)\n",
    "                return actions.FunctionCall(build_action, [[0], safe_coords(x, y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['gather'] and actions.FUNCTIONS.Harvest_Gather_screen.id in avail:\n",
    "        minerals = [u for u in fus if u.unit_type == 341]\n",
    "        if minerals:\n",
    "            target = random.choice(minerals)\n",
    "            return actions.FunctionCall(actions.FUNCTIONS.Harvest_Gather_screen.id, [[0], safe_coords(target.x, target.y)]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['upgrade']:\n",
    "        upgrade_actions = [a for a in avail if 'Research' in actions.FUNCTIONS[a].name]\n",
    "        if upgrade_actions:\n",
    "            upgrade_action = random.choice(upgrade_actions)\n",
    "            return actions.FunctionCall(upgrade_action, [[0]]), None\n",
    "\n",
    "    if action_idx == ACTION_INDEX['train']:\n",
    "        train_actions = [a for a in avail if 'Train' in actions.FUNCTIONS[a].name]\n",
    "        if train_actions:\n",
    "            train_action = random.choice(train_actions)\n",
    "            return actions.FunctionCall(train_action, [[0]]), None\n",
    "\n",
    "    return actions.FunctionCall(actions.FUNCTIONS.no_op.id, []), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95d4b4d6-c7fb-47f8-9b29-89ca20299c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO training LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f710a40-241f-4cef-91a8-4413a650d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pysc2.lib import actions\n",
    "from config import *\n",
    "# from utils import preprocess, legal_actions, make_pysc2_call\n",
    "\n",
    "\n",
    "# â”€â”€â”€ PPO Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def PPO(envs, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1.0, end_factor=0.0, total_iters=MAX_ITERS\n",
    "    )\n",
    "\n",
    "    ep_rewards = []       # final cumulative score of each episode\n",
    "    last_score = [0]*envs.nb\n",
    "\n",
    "    logger.info(\"â–¶ï¸  Starting PPO for %d iterations\", MAX_ITERS)\n",
    "    for it in range(MAX_ITERS):\n",
    "        if it % 1000 == 0:\n",
    "            logger.info(\"ğŸ”„ Iter %d / %d\", it, MAX_ITERS)\n",
    "\n",
    "        # storage buffers\n",
    "        obs_buf  = torch.zeros(envs.nb, T, 2, SCREEN_SIZE, SCREEN_SIZE, device=DEVICE)\n",
    "        act_buf  = torch.zeros(envs.nb, T,      dtype=torch.long, device=DEVICE)\n",
    "        logp_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        val_buf  = torch.zeros(envs.nb, T+1,                   device=DEVICE)\n",
    "        rew_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        done_buf = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "        adv_buf  = torch.zeros(envs.nb, T,                     device=DEVICE)\n",
    "\n",
    "        # â”€â”€â”€ Rollout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        with torch.no_grad():\n",
    "            for t in range(T):\n",
    "                for i in range(envs.nb):\n",
    "                    ts    = envs.obs[i]\n",
    "                    state = preprocess(ts)\n",
    "                    logits, value = model(state)\n",
    "\n",
    "                    # mask illegal\n",
    "                    LA   = legal_actions(ts)\n",
    "                    mask = torch.full_like(logits, float('-inf'))\n",
    "                    mask[0, LA] = 0.0\n",
    "                    dist = Categorical(logits=logits + mask)\n",
    "\n",
    "                    action = dist.sample()\n",
    "                    logp   = dist.log_prob(action)\n",
    "                    fc     = make_pysc2_call(action.item(), ts)\n",
    "\n",
    "                    # step (fallback to no-op)\n",
    "                    try:\n",
    "                        ts2 = envs.step(i, fc)\n",
    "                    except ValueError:\n",
    "                        ts2 = envs.step(i,\n",
    "                            actions.FunctionCall(actions.FUNCTIONS.no_op.id, []))\n",
    "\n",
    "                    # â”€â”€ reward = Î” score_cumulative â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "                    cur_score = int(ts2.observation['score_cumulative'][0])\n",
    "                    r = cur_score - last_score[i]\n",
    "                    last_score[i] = cur_score\n",
    "\n",
    "                    d = float(ts2.last())\n",
    "\n",
    "                    obs_buf[i,t]  = state\n",
    "                    act_buf[i,t]  = action\n",
    "                    logp_buf[i,t] = logp\n",
    "                    val_buf[i,t]  = value\n",
    "                    rew_buf[i,t]  = r\n",
    "                    done_buf[i,t] = d\n",
    "\n",
    "                    if d:\n",
    "                        ep_rewards.append(cur_score)\n",
    "                        last_score[i] = 0\n",
    "                        envs.reset(i)\n",
    "\n",
    "            # bootstrap final value\n",
    "            for i in range(envs.nb):\n",
    "                val_buf[i,T] = model(preprocess(envs.obs[i]))[1]\n",
    "\n",
    "        # â”€â”€â”€ GAE & flatten â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for i in range(envs.nb):\n",
    "            gae = 0\n",
    "            for t in reversed(range(T)):\n",
    "                mask  = 1.0 - done_buf[i,t]\n",
    "                delta = rew_buf[i,t] + GAMMA*val_buf[i,t+1]*mask - val_buf[i,t]\n",
    "                gae   = delta + GAMMA*GAE_LAMBDA*mask*gae\n",
    "                adv_buf[i,t] = gae\n",
    "\n",
    "        b_s  = obs_buf.reshape(-1,2,SCREEN_SIZE,SCREEN_SIZE)\n",
    "        b_a  = act_buf.reshape(-1)\n",
    "        b_lp = logp_buf.reshape(-1)\n",
    "        b_v  = val_buf[:,:T].reshape(-1)\n",
    "        b_ad = adv_buf.reshape(-1)\n",
    "\n",
    "        # â”€â”€â”€ PPO updates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        for _ in range(K):\n",
    "            ds     = TensorDataset(b_s,b_a,b_lp,b_v,b_ad)\n",
    "            loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "            for st, ac, old_lp, old_v, adv in loader:\n",
    "                logits, val = model(st)\n",
    "                dist        = Categorical(logits=logits)\n",
    "                lp          = dist.log_prob(ac)\n",
    "                ratio       = torch.exp(lp - old_lp)\n",
    "\n",
    "                clip   = 0.1 * (1 - it/MAX_ITERS)\n",
    "                obj1   = adv * ratio\n",
    "                obj2   = adv * torch.clamp(ratio, 1-clip, 1+clip)\n",
    "                p_loss = -torch.min(obj1,obj2).mean()\n",
    "\n",
    "                ret     = adv + old_v\n",
    "                v1      = (val - ret).pow(2)\n",
    "                v2      = (torch.clamp(val,old_v-clip,old_v+clip)-ret).pow(2)\n",
    "                v_loss  = 0.5 * torch.max(v1,v2).mean()\n",
    "\n",
    "                entropy = dist.entropy().mean()\n",
    "                loss    = p_loss + VF_COEF*v_loss - ENT_COEF*entropy\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(),0.5)\n",
    "                optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # â”€â”€â”€ Plot learning curve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(ep_rewards, label=\"final score per episode\")\n",
    "    plt.title(\"CollectMineralsAndGas: cumulative score\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"learning_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "    envs.close()\n",
    "    logger.info(\"âœ… Training complete\")\n",
    "    logger.info(f\"Saved learning_curve.png over {len(ep_rewards)} episodes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdcecead-f59c-4bbd-827d-771ad655c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "47d18d4c-cd99-477a-be83-74fd6005978b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from absl import app\n",
    "# # from environment import SC2Envs\n",
    "# # from model import ActorCritic\n",
    "# # from ppo import PPO\n",
    "# # from config import NB_ACTORS, DEVICE\n",
    "# # from utils import ACTION_LIST\n",
    "\n",
    "# def main(_):\n",
    "#     envs = SC2Envs(NB_ACTORS)\n",
    "#     model = ActorCritic(2, len(ACTION_LIST)).to(DEVICE)\n",
    "#     PPO(envs, model)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import sys\n",
    "#     sys.argv = sys.argv[:1]  # Remove extra flags passed by Jupyter or IPython\n",
    "#     app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "942d6802-c091-4439-9f6c-a28b16ccbb30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:26:31 [INFO] Initializing 1 SC2 env(s)...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Maps support 2 - 2 players, but trying to join with 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# from util import preprocess, legal_actions, make_pysc2_call\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# from env import SC2Envs\u001b[39;00m\n\u001b[32m     14\u001b[39m console = Console()\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m envs = \u001b[43mSC2Envs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_actor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m pending_action = [\u001b[38;5;28;01mNone\u001b[39;00m] * envs.nb\n\u001b[32m     18\u001b[39m MAX_ROWS = \u001b[32m20\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mSC2Envs.__init__\u001b[39m\u001b[34m(self, nb_actor)\u001b[39m\n\u001b[32m      7\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mInitializing \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m SC2 env(s)...\u001b[39m\u001b[33m\"\u001b[39m, nb_actor)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.nb   = nb_actor\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mself\u001b[39m.envs = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnb_actor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.obs  = [\u001b[38;5;28;01mNone\u001b[39;00m]*nb_actor\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.done = [\u001b[38;5;28;01mFalse\u001b[39;00m]*nb_actor\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      7\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mInitializing \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m SC2 env(s)...\u001b[39m\u001b[33m\"\u001b[39m, nb_actor)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mself\u001b[39m.nb   = nb_actor\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mself\u001b[39m.envs = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_actor)]\n\u001b[32m     10\u001b[39m \u001b[38;5;28mself\u001b[39m.obs  = [\u001b[38;5;28;01mNone\u001b[39;00m]*nb_actor\n\u001b[32m     11\u001b[39m \u001b[38;5;28mself\u001b[39m.done = [\u001b[38;5;28;01mFalse\u001b[39;00m]*nb_actor\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mSC2Envs._make_env\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_env\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msc2_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSC2Env\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAP_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplayers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msc2_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc2_env\u001b[49m\u001b[43m.\u001b[49m\u001b[43mRace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mterran\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43magent_interface_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAgentInterfaceFormat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_dimensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDimensions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                \u001b[49m\u001b[43mscreen\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSCREEN_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMINIMAP_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_feature_units\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_raw_units\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_camera_position\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mActionSpace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFEATURES\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep_mul\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTEP_MUL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgame_steps_per_episode\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Project\\starcraft_ai\\venv\\Lib\\site-packages\\pysc2\\env\\sc2_env.py:213\u001b[39m, in \u001b[36mSC2Env.__init__\u001b[39m\u001b[34m(self, map_name, battle_net_map, players, agent_interface_format, discount, discount_zero_after_timeout, visualize, step_mul, realtime, save_replay_episodes, replay_dir, replay_prefix, game_steps_per_episode, score_index, score_multiplier, random_seed, disable_fog, ensure_available_actions, version)\u001b[39m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSingle player maps require exactly one Agent.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m2\u001b[39m <= num_players <= min_players:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    214\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mMaps support 2 - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m players, but trying to join with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (\n\u001b[32m    215\u001b[39m           min_players, num_players))\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_replay_episodes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m replay_dir:\n\u001b[32m    218\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing replay_dir\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Maps support 2 - 2 players, but trying to join with 1"
     ]
    }
   ],
   "source": [
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "flags.FLAGS(sys.argv)  # fix required by pysc2\n",
    "# from util import preprocess, legal_actions, make_pysc2_call\n",
    "# from env import SC2Envs\n",
    "\n",
    "console = Console()\n",
    "envs = SC2Envs(nb_actor=1)\n",
    "pending_action = [None] * envs.nb\n",
    "\n",
    "MAX_ROWS = 20\n",
    "recent_rows = deque(maxlen=MAX_ROWS)\n",
    "\n",
    "# For tracking per-episode scores\n",
    "episode_score = [0] * envs.nb\n",
    "scores = []\n",
    "\n",
    "def generate_table():\n",
    "    table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "    table.add_column(\"Step\", justify=\"right\")\n",
    "    table.add_column(\"Function ID\", justify=\"right\")\n",
    "    table.add_column(\"Args\", justify=\"left\")\n",
    "    for row in recent_rows:\n",
    "        table.add_row(*row)\n",
    "    return table\n",
    "\n",
    "with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "    for step in range(MAX_ITERS):\n",
    "        for i in range(envs.nb):\n",
    "            ts = envs.obs[i]\n",
    "\n",
    "            if pending_action[i]:\n",
    "                action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "            else:\n",
    "                legal = legal_actions(ts)\n",
    "                action_idx = random.choice(legal)\n",
    "                action, pending_action[i] = make_pysc2_call(action_idx, ts)\n",
    "\n",
    "            recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "            live.update(generate_table())\n",
    "\n",
    "            ts = envs.step(i, action)\n",
    "            episode_score[i] += ts.reward\n",
    "\n",
    "            if ts.last():\n",
    "                scores.append(episode_score[i])\n",
    "                episode_score[i] = 0  # reset\n",
    "                envs.reset(i)\n",
    "\n",
    "envs.close()\n",
    "\n",
    "# Plot episode scores\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(scores, label=\"Episode Score\", marker='o', linewidth=1.5)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Score\")\n",
    "plt.title(\"Agent Score per Episode\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a1044ec-ea4c-4ed4-91c4-6cede1bb862f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Campain Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e3b570e-8f16-4ebf-ba44-aef48488f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         SC2 Agent Actions (Last 20 Steps)                                         </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">              Step </span>â”ƒ<span style=\"font-weight: bold\">                            Function ID </span>â”ƒ<span style=\"font-weight: bold\"> Args                                               </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚              9979 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9980 â”‚                                    331 â”‚ [[0], [73, 55]]                                    â”‚\n",
       "â”‚              9981 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9982 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9983 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9984 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9985 â”‚                                    490 â”‚ [[0]]                                              â”‚\n",
       "â”‚              9986 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9987 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9988 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9989 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9990 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9991 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9992 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9993 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9994 â”‚                                     91 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9995 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9996 â”‚                                    331 â”‚ [[0], [30, 2]]                                     â”‚\n",
       "â”‚              9997 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9998 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         SC2 Agent Actions (Last 20 Steps)                                         \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m             Step\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                           Function ID\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mArgs                                              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚              9979 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9980 â”‚                                    331 â”‚ [[0], [73, 55]]                                    â”‚\n",
       "â”‚              9981 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9982 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9983 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9984 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9985 â”‚                                    490 â”‚ [[0]]                                              â”‚\n",
       "â”‚              9986 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9987 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9988 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9989 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9990 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9991 â”‚                                      0 â”‚ []                                                 â”‚\n",
       "â”‚              9992 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9993 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9994 â”‚                                     91 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9995 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9996 â”‚                                    331 â”‚ [[0], [30, 2]]                                     â”‚\n",
       "â”‚              9997 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â”‚              9998 â”‚                                      2 â”‚ [[0], ]                                            â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:41:02 [INFO] Environment Close\n",
      "14:41:02 [INFO] Shutdown gracefully.\n",
      "14:41:02 [INFO] Shutdown with return code: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.live import Live\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "from absl import flags\n",
    "\n",
    "flags.FLAGS(sys.argv)  # fix required by pysc2\n",
    "# from util import preprocess, legal_actions, make_pysc2_call\n",
    "# from env import SC2Envs\n",
    "\n",
    "console = Console()\n",
    "envs = SC2EnvsMulti(nb_actor=1)\n",
    "pending_action = [None] * envs.nb\n",
    "\n",
    "MAX_ROWS = 20\n",
    "recent_rows = deque(maxlen=MAX_ROWS)\n",
    "\n",
    "# For tracking per-episode scores\n",
    "episode_score = [0] * envs.nb\n",
    "scores = []\n",
    "\n",
    "def generate_table():\n",
    "    table = Table(title=f\"SC2 Agent Actions (Last {MAX_ROWS} Steps)\", expand=True)\n",
    "    table.add_column(\"Step\", justify=\"right\")\n",
    "    table.add_column(\"Function ID\", justify=\"right\")\n",
    "    table.add_column(\"Args\", justify=\"left\")\n",
    "    for row in recent_rows:\n",
    "        table.add_row(*row)\n",
    "    return table\n",
    "\n",
    "with Live(generate_table(), refresh_per_second=10, console=console, transient=True) as live:\n",
    "    for step in range(MAX_ITERS):\n",
    "        for i in range(envs.nb):\n",
    "            ts = envs.obs[i]\n",
    "\n",
    "            if pending_action[i]:\n",
    "                action, pending_action[i] = make_pysc2_call(None, ts, pending_action[i])\n",
    "            else:\n",
    "                legal = legal_actions(ts)\n",
    "                action_idx = random.choice(legal)\n",
    "                action, pending_action[i] = make_pysc2_call(action_idx, ts)\n",
    "\n",
    "            recent_rows.append((str(step), str(action.function), str(action.arguments)))\n",
    "            live.update(generate_table())\n",
    "\n",
    "            ts = envs.step(i, action)\n",
    "            episode_score[i] += ts.reward\n",
    "\n",
    "            if ts.last():\n",
    "                scores.append(episode_score[i])\n",
    "                episode_score[i] = 0  # reset\n",
    "                envs.reset(i)\n",
    "\n",
    "envs.close()\n",
    "\n",
    "# Plot episode scores\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(reward, label=\"Episode Score\", marker='o', linewidth=1.5)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Score\")\n",
    "plt.title(\"Agent Score per Episode\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87a1e3-1c57-41da-a461-9c6a4a0b6d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
